{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLORES+\n",
    "\n",
    "[FLORES+ on HuggingFace](https://huggingface.co/datasets/openlanguagedata/flores_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from datasets import load_dataset\n",
    "from joblib import Parallel, delayed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "folder_path = '../../python_library'\n",
    "sys.path.append(os.path.abspath(folder_path))\n",
    "from token_scoring import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0dc66a053104b36a9ffcdeb955f58f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "174e2911a64f43bc94467d55869aad56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f9b4e14c1647e9b116671d3da53ac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbd86a2c7b47446a900099ecca576a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcdfb0f395b84b929527967830523989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4a002ecdb34cafaa3f3cf9f3c08049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a106642cca432895530cc13eeb2237",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/218 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ee2244aa784d20aa5dfed7a2d26c58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load FLORES+ \n",
    "flores_plus = load_dataset(\"openlanguagedata/flores_plus\")\n",
    "\n",
    "# Load FLORES dev split and convert to Pandas DataFrame\n",
    "flores_plus_dev = load_dataset(\"openlanguagedata/flores_plus\", split='dev').to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(217346, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>iso_639_3</th>\n",
       "      <th>language</th>\n",
       "      <th>glottocode</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>topic</th>\n",
       "      <th>has_image</th>\n",
       "      <th>has_hyperlink</th>\n",
       "      <th>last_updated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ace</td>\n",
       "      <td>Arab</td>\n",
       "      <td>achi1257</td>\n",
       "      <td>يق أورو سنين، اوق علمون دري فکولتس کدوکترن يون...</td>\n",
       "      <td>https://en.wikinews.org/wiki/Scientists_say_ne...</td>\n",
       "      <td>wikinews</td>\n",
       "      <td>health</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ace</td>\n",
       "      <td>Arab</td>\n",
       "      <td>achi1257</td>\n",
       "      <td>ڤنليتي اوتام خن اترا ڽو موڠکين محسى ديتيکسي فو...</td>\n",
       "      <td>https://en.wikinews.org/wiki/Scientists_say_ne...</td>\n",
       "      <td>wikinews</td>\n",
       "      <td>health</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id iso_639_3 language glottocode  \\\n",
       "0   0       ace     Arab   achi1257   \n",
       "1   1       ace     Arab   achi1257   \n",
       "\n",
       "                                                text  \\\n",
       "0  يق أورو سنين، اوق علمون دري فکولتس کدوکترن يون...   \n",
       "1  ڤنليتي اوتام خن اترا ڽو موڠکين محسى ديتيکسي فو...   \n",
       "\n",
       "                                                 url    domain   topic  \\\n",
       "0  https://en.wikinews.org/wiki/Scientists_say_ne...  wikinews  health   \n",
       "1  https://en.wikinews.org/wiki/Scientists_say_ne...  wikinews  health   \n",
       "\n",
       "  has_image has_hyperlink last_updated  \n",
       "0       yes           yes          1.0  \n",
       "1       yes           yes          1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flores_plus_dev = flores_plus_dev.rename(columns={'iso_15924':'language'})\n",
    "print(flores_plus_dev.shape)\n",
    "flores_plus_dev.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 31 in the FLORES+ dataset:\n",
      "['Arab' 'Latn' 'Ethi' 'Beng' 'Deva' 'Cyrl' 'Tibt' 'Hans' 'Hant' 'Grek'\n",
      " 'Gujr' 'Hebr' 'Armn' 'Jpan' 'Knda' 'Geor' 'Khmr' 'Hang' 'Laoo' 'Mlym'\n",
      " 'Mtei' 'Mymr' 'Nkoo' 'Orya' 'Guru' 'Olck' 'Sinh' 'Taml' 'Tfng' 'Telu'\n",
      " 'Thai']\n"
     ]
    }
   ],
   "source": [
    "# Get unique languages\n",
    "print(f\"There are {len(flores_plus_dev['language'].unique())} in the FLORES+ dataset:\")\n",
    "print(flores_plus_dev['language'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with google/flan-t5-xxl\n",
      "Done with bigscience/mt0-xxl-mt\n",
      "Done with CohereForAI/aya-101\n",
      "Done with bigscience/bloomz-7b1\n",
      "Done with microsoft/Phi-3.5-mini-instruct\n",
      "Done with neulab/Pangea-7B\n",
      "Done with google/gemma-7b\n",
      "Done with google/gemma-2-9b\n",
      "Done with meta-llama/Llama-3.2-1B-Instruct\n"
     ]
    }
   ],
   "source": [
    "models = [\"google/flan-t5-xxl\",\n",
    "          \"bigscience/mt0-xxl-mt\",\n",
    "          \"CohereForAI/aya-101\",\n",
    "          \"bigscience/bloomz-7b1\",\n",
    "          \"microsoft/Phi-3.5-mini-instruct\",\n",
    "          \"neulab/Pangea-7B\",\n",
    "          \"google/gemma-7b\",\n",
    "          \"google/gemma-2-9b\",\n",
    "          \"meta-llama/Llama-3.2-1B-Instruct\"]\n",
    "names_for_csv = ['flan-t5-xxl',\n",
    "                 'mt0-xxl-mt',\n",
    "                 'aya-101',\n",
    "                 'bloomz-7b1',\n",
    "                 'Phi-3.5-mini-instruct',\n",
    "                 'Pangea-7B',\n",
    "                 'gemma-7b',\n",
    "                 'gemma-2-9b', \n",
    "                 'Llama-3.2-1B-Instruct']\n",
    "\n",
    "dfs = []\n",
    "for i in range(len(models)):\n",
    "    scored = get_parities(data=flores_plus_dev, \n",
    "                             tokenizer=AutoTokenizer.from_pretrained(models[i]), \n",
    "                             visualize=False)\n",
    "    scored['model'] = models[i]\n",
    "    dfs.append(scored)\n",
    "    print(f'Done with {models[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>iso_639_3</th>\n",
       "      <th>language</th>\n",
       "      <th>glottocode</th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "      <th>domain</th>\n",
       "      <th>topic</th>\n",
       "      <th>has_image</th>\n",
       "      <th>has_hyperlink</th>\n",
       "      <th>last_updated</th>\n",
       "      <th>parity</th>\n",
       "      <th>tokens</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>ace</td>\n",
       "      <td>Arab</td>\n",
       "      <td>achi1257</td>\n",
       "      <td>يق أورو سنين، اوق علمون دري فکولتس کدوکترن يون...</td>\n",
       "      <td>https://en.wikinews.org/wiki/Scientists_say_ne...</td>\n",
       "      <td>wikinews</td>\n",
       "      <td>health</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.155556</td>\n",
       "      <td>[▁, يق, ▁, أورو, ▁, سنين،, ▁, اوق, ▁, علمون, ▁...</td>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>ace</td>\n",
       "      <td>Arab</td>\n",
       "      <td>achi1257</td>\n",
       "      <td>ڤنليتي اوتام خن اترا ڽو موڠکين محسى ديتيکسي فو...</td>\n",
       "      <td>https://en.wikinews.org/wiki/Scientists_say_ne...</td>\n",
       "      <td>wikinews</td>\n",
       "      <td>health</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.307692</td>\n",
       "      <td>[▁, ڤنليتي, ▁, اوتام, ▁, خن, ▁, اترا, ▁, ڽو, ▁...</td>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id iso_639_3 language glottocode  \\\n",
       "0   0       ace     Arab   achi1257   \n",
       "1   1       ace     Arab   achi1257   \n",
       "\n",
       "                                                text  \\\n",
       "0  يق أورو سنين، اوق علمون دري فکولتس کدوکترن يون...   \n",
       "1  ڤنليتي اوتام خن اترا ڽو موڠکين محسى ديتيکسي فو...   \n",
       "\n",
       "                                                 url    domain   topic  \\\n",
       "0  https://en.wikinews.org/wiki/Scientists_say_ne...  wikinews  health   \n",
       "1  https://en.wikinews.org/wiki/Scientists_say_ne...  wikinews  health   \n",
       "\n",
       "  has_image has_hyperlink last_updated    parity  \\\n",
       "0       yes           yes          1.0  2.155556   \n",
       "1       yes           yes          1.0  2.307692   \n",
       "\n",
       "                                              tokens               model  \n",
       "0  [▁, يق, ▁, أورو, ▁, سنين،, ▁, اوق, ▁, علمون, ▁...  google/flan-t5-xxl  \n",
       "1  [▁, ڤنليتي, ▁, اوتام, ▁, خن, ▁, اترا, ▁, ڽو, ▁...  google/flan-t5-xxl  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parities = pd.concat(dfs, ignore_index=True)\n",
    "parities.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (911368 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with google/flan-t5-xxl\n",
      "Done with bigscience/mt0-xxl-mt\n",
      "Done with CohereForAI/aya-101\n",
      "Done with bigscience/bloomz-7b1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (2505498 > 131072). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with microsoft/Phi-3.5-mini-instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1397776 > 8192). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with neulab/Pangea-7B\n",
      "Done with google/gemma-7b\n",
      "Done with google/gemma-2-9b\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1319075 > 131072). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with meta-llama/Llama-3.2-1B-Instruct\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>corpus</th>\n",
       "      <th>fertility</th>\n",
       "      <th>tokens</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arab</td>\n",
       "      <td>يق أورو سنين، اوق علمون دري فکولتس کدوکترن يون...</td>\n",
       "      <td>2.078433</td>\n",
       "      <td>[▁, يق, ▁, أورو, ▁, سنين،, ▁, اوق, ▁, علمون, ▁...</td>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Latn</td>\n",
       "      <td>Bak uroe Senin, awak ilmuwan dari Fakultas Ked...</td>\n",
       "      <td>3.436214</td>\n",
       "      <td>[▁Bak, ▁, ur, o, e, ▁Sen, in, ,, ▁, a, wak, ▁,...</td>\n",
       "      <td>google/flan-t5-xxl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language                                             corpus  fertility  \\\n",
       "0     Arab  يق أورو سنين، اوق علمون دري فکولتس کدوکترن يون...   2.078433   \n",
       "1     Latn  Bak uroe Senin, awak ilmuwan dari Fakultas Ked...   3.436214   \n",
       "\n",
       "                                              tokens               model  \n",
       "0  [▁, يق, ▁, أورو, ▁, سنين،, ▁, اوق, ▁, علمون, ▁...  google/flan-t5-xxl  \n",
       "1  [▁Bak, ▁, ur, o, e, ▁Sen, in, ,, ▁, a, wak, ▁,...  google/flan-t5-xxl  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for i in range(len(models)):\n",
    "    scored = get_fertilities(data=flores_plus_dev, \n",
    "                             tokenizer=AutoTokenizer.from_pretrained(models[i]), \n",
    "                             visualize=False)\n",
    "    scored['model'] = models[i]\n",
    "    dfs.append(scored)\n",
    "    print(f'Done with {models[i]}')\n",
    "\n",
    "\n",
    "fertilities = pd.concat(dfs, ignore_index=True)\n",
    "fertilities.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "parities.to_csv('model_parities_using_library.csv')\n",
    "fertilities.to_csv('model_fertilities_using_library.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CohereForAI/aya-101</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6.329727</td>\n",
       "      <td>7.314511</td>\n",
       "      <td>2.104427</td>\n",
       "      <td>2.600421</td>\n",
       "      <td>3.012729</td>\n",
       "      <td>6.108890</td>\n",
       "      <td>30.143799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigscience/bloomz-7b1</th>\n",
       "      <td>31.0</td>\n",
       "      <td>11.939275</td>\n",
       "      <td>12.950681</td>\n",
       "      <td>1.514487</td>\n",
       "      <td>2.258471</td>\n",
       "      <td>6.058881</td>\n",
       "      <td>16.073491</td>\n",
       "      <td>44.211665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bigscience/mt0-xxl-mt</th>\n",
       "      <td>31.0</td>\n",
       "      <td>6.329727</td>\n",
       "      <td>7.314511</td>\n",
       "      <td>2.104427</td>\n",
       "      <td>2.600421</td>\n",
       "      <td>3.012729</td>\n",
       "      <td>6.108890</td>\n",
       "      <td>30.143799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/flan-t5-xxl</th>\n",
       "      <td>31.0</td>\n",
       "      <td>2.602669</td>\n",
       "      <td>1.048444</td>\n",
       "      <td>2.040513</td>\n",
       "      <td>2.090918</td>\n",
       "      <td>2.143660</td>\n",
       "      <td>2.222407</td>\n",
       "      <td>5.829346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-2-9b</th>\n",
       "      <td>31.0</td>\n",
       "      <td>8.476900</td>\n",
       "      <td>7.593213</td>\n",
       "      <td>2.120740</td>\n",
       "      <td>3.635907</td>\n",
       "      <td>5.591380</td>\n",
       "      <td>9.177739</td>\n",
       "      <td>28.918156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>google/gemma-7b</th>\n",
       "      <td>31.0</td>\n",
       "      <td>8.476900</td>\n",
       "      <td>7.593213</td>\n",
       "      <td>2.120740</td>\n",
       "      <td>3.635907</td>\n",
       "      <td>5.591380</td>\n",
       "      <td>9.177739</td>\n",
       "      <td>28.918156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-3.2-1B-Instruct</th>\n",
       "      <td>31.0</td>\n",
       "      <td>16.422128</td>\n",
       "      <td>14.790794</td>\n",
       "      <td>2.402349</td>\n",
       "      <td>8.412023</td>\n",
       "      <td>12.358785</td>\n",
       "      <td>16.518693</td>\n",
       "      <td>72.014839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>microsoft/Phi-3.5-mini-instruct</th>\n",
       "      <td>31.0</td>\n",
       "      <td>19.731495</td>\n",
       "      <td>16.967171</td>\n",
       "      <td>2.618073</td>\n",
       "      <td>8.457879</td>\n",
       "      <td>12.159142</td>\n",
       "      <td>25.789270</td>\n",
       "      <td>62.217310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>neulab/Pangea-7B</th>\n",
       "      <td>31.0</td>\n",
       "      <td>13.045482</td>\n",
       "      <td>10.661878</td>\n",
       "      <td>2.400613</td>\n",
       "      <td>6.380682</td>\n",
       "      <td>9.187998</td>\n",
       "      <td>16.370472</td>\n",
       "      <td>48.148746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  count       mean        std       min  \\\n",
       "model                                                                     \n",
       "CohereForAI/aya-101                31.0   6.329727   7.314511  2.104427   \n",
       "bigscience/bloomz-7b1              31.0  11.939275  12.950681  1.514487   \n",
       "bigscience/mt0-xxl-mt              31.0   6.329727   7.314511  2.104427   \n",
       "google/flan-t5-xxl                 31.0   2.602669   1.048444  2.040513   \n",
       "google/gemma-2-9b                  31.0   8.476900   7.593213  2.120740   \n",
       "google/gemma-7b                    31.0   8.476900   7.593213  2.120740   \n",
       "meta-llama/Llama-3.2-1B-Instruct   31.0  16.422128  14.790794  2.402349   \n",
       "microsoft/Phi-3.5-mini-instruct    31.0  19.731495  16.967171  2.618073   \n",
       "neulab/Pangea-7B                   31.0  13.045482  10.661878  2.400613   \n",
       "\n",
       "                                       25%        50%        75%        max  \n",
       "model                                                                        \n",
       "CohereForAI/aya-101               2.600421   3.012729   6.108890  30.143799  \n",
       "bigscience/bloomz-7b1             2.258471   6.058881  16.073491  44.211665  \n",
       "bigscience/mt0-xxl-mt             2.600421   3.012729   6.108890  30.143799  \n",
       "google/flan-t5-xxl                2.090918   2.143660   2.222407   5.829346  \n",
       "google/gemma-2-9b                 3.635907   5.591380   9.177739  28.918156  \n",
       "google/gemma-7b                   3.635907   5.591380   9.177739  28.918156  \n",
       "meta-llama/Llama-3.2-1B-Instruct  8.412023  12.358785  16.518693  72.014839  \n",
       "microsoft/Phi-3.5-mini-instruct   8.457879  12.159142  25.789270  62.217310  \n",
       "neulab/Pangea-7B                  6.380682   9.187998  16.370472  48.148746  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fertilities.groupby('model')['fertility'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
