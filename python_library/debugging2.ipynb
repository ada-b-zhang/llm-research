{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a file to create token IDs for unit testing. \n",
    "\n",
    "Use [The Tokenizer Playground](https://huggingface.co/spaces/Xenova/the-tokenizer-playground) to verify token IDs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_IDs(text, model=\"microsoft/Phi-3.5-mini-instruct\"): \n",
    "    \"\"\" \n",
    "    Get token IDs given some text and model. \n",
    "\n",
    "    Parameters\n",
    "    ---------- \n",
    "        - text (str): text for which to get token IDs\n",
    "        - model (model): model to use as tokenizer\n",
    "\n",
    "    Returns\n",
    "    ------- \n",
    "    tuple of (tokens, token_IDs)\n",
    "        - tokens (list): list of tokens for input text \n",
    "        - token_IDs (list): list of token IDs for each token  \n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model) \n",
    "    tokens = tokenizer.tokenize(text) \n",
    "    token_IDs = tokenizer.encode(text, add_special_tokens=True)\n",
    "\n",
    "    return tokens, token_IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['▁Hello', ',', '▁how', '▁are', '▁you', '?']\n",
      "[15043, 29892, 920, 526, 366, 29973]\n"
     ]
    }
   ],
   "source": [
    "text = 'Hello, how are you?'\n",
    "tokens, token_IDs = get_token_IDs(text)\n",
    "print(tokens)\n",
    "print(token_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\"The sky is bright today.\", \n",
    "         \"I love classical music.\", \n",
    "         \"Data science is fascinating.\", \n",
    "         \"Could you pass the salt?\", \n",
    "         \"Baroque composers inspire my work.\", \n",
    "         \"What time is the meeting?\", \n",
    "         \"This coffee tastes really good.\",\n",
    "         \"Purple is pretty\"]\n",
    "tokens = []\n",
    "token_IDs = []\n",
    "for text in texts:\n",
    "    tokens_, token_IDs_ = get_token_IDs(text)\n",
    "    tokens.append(tokens_)\n",
    "    token_IDs.append(token_IDs_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁The', '▁sky', '▁is', '▁bright', '▁today', '.'],\n",
       " ['▁I', '▁love', '▁classical', '▁music', '.'],\n",
       " ['▁Data', '▁science', '▁is', '▁fasc', 'in', 'ating', '.'],\n",
       " ['▁Could', '▁you', '▁pass', '▁the', '▁salt', '?'],\n",
       " ['▁Bar', 'o', 'que', '▁compos', 'ers', '▁insp', 'ire', '▁my', '▁work', '.'],\n",
       " ['▁What', '▁time', '▁is', '▁the', '▁meeting', '?'],\n",
       " ['▁This', '▁coffee', '▁t', 'ast', 'es', '▁really', '▁good', '.'],\n",
       " ['▁Pur', 'ple', '▁is', '▁pretty']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[450, 14744, 338, 11785, 9826, 29889],\n",
       " [306, 5360, 14499, 4696, 29889],\n",
       " [3630, 10466, 338, 21028, 262, 1218, 29889],\n",
       " [6527, 366, 1209, 278, 15795, 29973],\n",
       " [2261, 29877, 802, 5541, 414, 8681, 533, 590, 664, 29889],\n",
       " [1724, 931, 338, 278, 11781, 29973],\n",
       " [910, 26935, 260, 579, 267, 2289, 1781, 29889],\n",
       " [15247, 552, 338, 5051]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create dataframe of expected tokens and token IDs for each model and text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\"google/flan-t5-xxl\",\n",
    "          \"bigscience/mt0-xxl-mt\",\n",
    "          \"CohereForAI/aya-101\",\n",
    "          \"bigscience/bloomz-7b1\",\n",
    "          \"microsoft/Phi-3.5-mini-instruct\",\n",
    "          \"neulab/Pangea-7B\",\n",
    "          \"google/gemma-7b\",\n",
    "          \"google/gemma-2-9b\",\n",
    "          \"meta-llama/Llama-3.2-1B-Instruct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['▁The', '▁sky', '▁is', '▁bright', '▁today', '.'],\n",
       " ['▁I', '▁love', '▁classical', '▁music', '.'],\n",
       " ['▁Data', '▁science', '▁is', '▁fascinating', '.'],\n",
       " ['▁Could', '▁you', '▁pass', '▁the', '▁salt', '?'],\n",
       " ['▁Bar', 'o', 'que', '▁composer', 's', '▁inspire', '▁my', '▁work', '.'],\n",
       " ['▁What', '▁time', '▁is', '▁the', '▁meeting', '?'],\n",
       " ['▁This', '▁coffee', '▁tastes', '▁really', '▁good', '.'],\n",
       " ['▁Purple', '▁is', '▁pretty']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model: google/flan-t5-xxl\n",
    "tokens = []\n",
    "token_IDs = []\n",
    "for text in texts:\n",
    "    tokens_, token_IDs_ = get_token_IDs(text, model='google/flan-t5-xxl')\n",
    "    tokens.append(tokens_)\n",
    "    token_IDs.append(token_IDs_)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this as part of unit tests. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
